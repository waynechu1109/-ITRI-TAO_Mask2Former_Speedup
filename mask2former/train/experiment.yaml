encryption_key: null
results_dir: /results/train
wandb:
  enable: true
  project: TAO Toolkit
  entity: ''
  tags:
  - training
  - tao-toolkit
  reinit: false
  sync_tensorboard: false
  save_code: false
  name: TAO Toolkit training experiment
model:
  export: false
  backbone:
    type: swin
    pretrained_weights: /workspace/tao-experiments/mask2former/swin_tiny_patch4_window7_224_22k.pth
    swin:
      type: tiny
      embed_dim: 96
      depths:
      - 2
      - 2
      - 6
      - 2
      num_heads:
      - 3
      - 6
      - 12
      - 24
      patch_size: 4
      window_size: 7
      mlp_ratio: 4.0
      qkv_bias: true
      qk_scale: null
      drop_rate: 0.0
      attn_drop_rate: 0.0
      drop_path_rate: 0.3
      ape: false
      patch_norm: true
      out_indices:
      - 0
      - 1
      - 2
      - 3
      pretrain_img_size: 224
      use_checkpoint: false
      out_features:
      - res2
      - res3
      - res4
      - res5
    efficientvit:
      name: l0
      out_indices:
      - 1
      - 2
      - 3
      pretrain_img_size: 384
      use_checkpoint: false
      out_features:
      - res2
      - res3
      - res4
      - res5
  sem_seg_head:
    common_stride: 4
    transformer_enc_layers: 6
    convs_dim: 256
    mask_dim: 256
    deformable_transformer_encoder_in_features:
    - res3
    - res4
    - res5
    num_classes: 222
    norm: GN
  mask_former:
    dropout: 0.0
    nheads: 8
    num_object_queries: 100
    hidden_dim: 256
    dim_feedforward: 2048
    dec_layers: 10
    pre_norm: false
    class_weight: 2.0
    dice_weight: 5.0
    mask_weight: 5.0
    train_num_points: 12544
    oversample_ratio: 3.0
    importance_sample_ratio: 0.75
    deep_supervision: true
    no_object_weight: 0.1
  mode: instance
  object_mask_threshold: 0.1
  overlap_threshold: 0.8
  test_topk_per_image: 100
dataset:
  train:
    type: coco
    name: coco_2020_train
    panoptic_json: /datasets/coco/annotations/panoptic_train2017.json
    instance_json: /data/raw-data/annotations/training_shape_training2020.json
    img_dir: /data/raw-data/training
    panoptic_dir: /datasets/coco/train2017
    root_dir: ''
    annot_file: ''
    batch_size: 16
    num_workers: 2
    target_size: []
  val:
    type: coco
    name: coco_2020_val
    panoptic_json: /datasets/coco/annotations/panoptic_train2017.json
    instance_json: /data/raw-data/annotations/training_shape_training2020.json
    img_dir: /data/raw-data/training
    panoptic_dir: /datasets/coco/train2017
    root_dir: ''
    annot_file: ''
    batch_size: 1
    num_workers: 2
    target_size: []
  test:
    type: ade
    name: ''
    panoptic_json: /datasets/coco/annotations/panoptic_train2017.json
    instance_json: /datasets/coco/annotations/instances_train2017.json
    img_dir: /data/raw-data/validation
    panoptic_dir: /datasets/coco/train2017
    root_dir: ''
    annot_file: ''
    batch_size: 1
    num_workers: 1
    target_size: []
  workers: 8
  pin_memory: true
  pixel_mean:
  - 0.485
  - 0.456
  - 0.406
  pixel_std:
  - 0.229
  - 0.224
  - 0.225
  augmentation:
    train_min_size:
    - 640
    train_max_size: 2048
    train_crop_size:
    - 640
    - 640
    test_min_size: 640
    test_max_size: 2048
  contiguous_id: true
  label_map: /specs/merged_labelmap.json
train:
  num_gpus: 1
  gpu_ids:
  - 0
  num_nodes: 1
  seed: 1234
  cudnn:
    benchmark: false
    deterministic: true
  num_epochs: 40
  checkpoint_interval: 1
  validation_interval: 1
  resume_training_checkpoint_path: null
  results_dir: /results/train
  freeze: []
  pretrained_model_path: null
  clip_grad_norm: 0.1
  clip_grad_norm_type: 2.0
  clip_grad_type: full
  is_dry_run: false
  optim:
    type: AdamW
    monitor_name: train_loss
    lr: 0.0001
    backbone_multiplier: 0.1
    momentum: 0.9
    weight_decay: 0.05
    lr_scheduler: MultiStep
    milestones:
    - 34
    - 38
    gamma: 0.1
  precision: fp16
  distributed_strategy: ddp
  activation_checkpoint: true
  verbose: false
  iters_per_epoch: null
inference:
  num_gpus: 1
  gpu_ids:
  - 0
  num_nodes: 1
  checkpoint: ???
  results_dir: null
  trt_engine: null
evaluate:
  num_gpus: 1
  gpu_ids:
  - 0
  num_nodes: 1
  checkpoint: ???
  results_dir: null
  trt_engine: null
export:
  results_dir: null
  gpu_id: 0
  checkpoint: ???
  onnx_file: ???
  on_cpu: false
  input_channel: 3
  input_width: 640
  input_height: 640
  opset_version: 17
  batch_size: -1
  verbose: false
gen_trt_engine:
  results_dir: null
  gpu_id: 0
  onnx_file: ???
  trt_engine: null
  input_channel: 3
  input_width: 640
  input_height: 640
  opset_version: 17
  batch_size: -1
  verbose: false
  tensorrt:
    data_type: fp16
    workspace_size: 4096
    min_batch_size: 1
    opt_batch_size: 1
    max_batch_size: 1
